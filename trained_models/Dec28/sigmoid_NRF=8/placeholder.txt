def Autoencoder_Encoding_module(input_shape, i=0, code_size=15, normalization=False):
    inputs = Input(input_shape, dtype=tf.float32)
    if normalization:
        min = tf.tile(tf.expand_dims(tf.reduce_min(inputs, axis=2), axis=2), (1, 1, inputs.shape[2]))
        max = tf.tile(tf.expand_dims(tf.reduce_max(inputs, axis=2), axis=2), (1, 1, inputs.shape[2]))
        x = (inputs - min) / (max - min)
    else:
        x = inputs
    x = Dense(128, kernel_initializer=tf.keras.initializers.he_normal(), name="encoder_{}_dense_1".format(i))(x)
    x = sigmoid(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = Dense(code_size, kernel_initializer=tf.keras.initializers.he_normal(), name="encoder_{}_dense_2".format(i))(x)
    return Model(inputs, x, name="encoder_{}".format(i))

def Autoencoder_Decoding_module(output_size, input_shape, i=0):
    inputs = Input(input_shape)
    x = Dense(128, kernel_initializer=tf.keras.initializers.he_normal(), name="decoder_{}_dense_1".format(i))(inputs)
    x = sigmoid(x)
    x = tf.keras.layers.BatchNormalization()(x)
    x = Dense(output_size, kernel_initializer=tf.keras.initializers.he_normal(), name="decoder_{}_dense_2".format(i))(x)
    return Model(inputs, x, name="decoder_{}".format(i))