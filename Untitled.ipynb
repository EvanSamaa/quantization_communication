{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.data import Dataset\n",
    "from tensorflow.keras import Model\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, Softmax, Input\n",
    "from tensorflow.keras.activations import sigmoid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/evansamaa/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'tensorflow.python.keras.api._v1.keras.metrics' has no attribute 'ExpectedThroughput'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-e05dd4ec1b2f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mtrain_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExpectedThroughput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'train_throughput'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mtest_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test_loss'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSparseCategoricalAccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'test_accuracy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/tensorflow/python/util/deprecation_wrapper.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'_dw_'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Accessing local variables before they are created.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m     \u001b[0mattr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dw_wrapped_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m     if (self._dw_warning_count < _PER_MODULE_WARNING_LIMIT and\n\u001b[1;32m    108\u001b[0m         name not in self._dw_deprecated_printed):\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'tensorflow.python.keras.api._v1.keras.metrics' has no attribute 'ExpectedThroughput'"
     ]
    }
   ],
   "source": [
    "class ExpectedThroughput(tf.keras.metrics.Metric):\n",
    "    def __init__(self, name='expected_throughput', **kwargs):\n",
    "        super(ExpectedThroughput, self).__init__(name=name, **kwargs)\n",
    "        self.throughput = self.add_weight(name='tp', initializer='zeros')\n",
    "    def update_state(self, y_true, y_pred, x):\n",
    "        print(y_true)\n",
    "        print(y_pred)\n",
    "\n",
    "    def result(self):\n",
    "        return self.throughput\n",
    "\n",
    "def create_model(input_shape, k):\n",
    "    inputs = Input(shape=input_shape)\n",
    "    x = perception_model(inputs, k, 3)\n",
    "    model = Model(inputs, x, name=\"max_nn\")\n",
    "    return model\n",
    "\n",
    "def perception_model(x, output, layer, logit=True):\n",
    "    for i in range(layer-1):\n",
    "        x = Dense(50)(x)\n",
    "        x = LeakyReLU()(x)\n",
    "    x = Dense(output)(x)\n",
    "    if logit:\n",
    "        return x\n",
    "    else:\n",
    "        return Softmax(x)\n",
    "\n",
    "def gen_data(N, k, low=0, high=1, batchsize=50):\n",
    "    channel_data = tf.random.uniform((N,k), low, high)\n",
    "    channel_label = tf.math.argmax(channel_data, axis=1)\n",
    "    dataset = Dataset.from_tensor_slices((channel_data, channel_label)).batch(batchsize)\n",
    "    return dataset\n",
    "def train_step(features, labels):\n",
    "    with tf.GradientTape() as tape:\n",
    "    # training=True is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "        predictions = model(features)\n",
    "        loss = loss_object(labels, predictions)\n",
    "    gradients = tape.gradient(loss, model.trainable_variables)\n",
    "    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n",
    "    train_loss(loss)\n",
    "    train_accuracy(labels, predictions)\n",
    "def test_step(features, labels):\n",
    "    # training=False is only needed if there are layers with different\n",
    "    # behavior during training versus inference (e.g. Dropout).\n",
    "    predictions = model(features)\n",
    "    t_loss = loss_object(labels, predictions)\n",
    "    test_loss(t_loss)\n",
    "    test_accuracy(labels, predictions)\n",
    "def test_model():\n",
    "    new_model = tf.keras.models.load_model('models/three_layer_MLP')\n",
    "    test_ds = gen_data(100, 10, 0, 1).batch(1)\n",
    "    for features, labels in test_ds:\n",
    "        prediction = new_model.predict(features)\n",
    "        print(prediction, labels)\n",
    "if __name__ == \"__main__\":\n",
    "    N = 10000\n",
    "    k = 30\n",
    "    EPOCHS = 1800\n",
    "    model = create_model((k,), k)\n",
    "    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "    optimizer = tf.keras.optimizers.Adam()\n",
    "    train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
    "    train_accuracy = tf.keras.metrics.ExpectedThroughput(name='train_throughput')\n",
    "    test_loss = tf.keras.metrics.Mean(name='test_loss')\n",
    "    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n",
    "    train_ds = gen_data(10000, k, 0, 1)\n",
    "    test_ds = gen_data(100, k, 0, 1)\n",
    "    # cycle = {0:(0,1), 1:(0,2), 2:(2,3), 3:(4,5), 4:(6,7), 5:(1,3)}\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        # Reset the metrics at the start of the next epoch\n",
    "        train_loss.reset_states()\n",
    "        train_accuracy.reset_states()\n",
    "        test_loss.reset_states()\n",
    "        test_accuracy.reset_states()\n",
    "        for features, labels in train_ds:\n",
    "            train_step(features, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
